{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644f8fa7-ba5a-4094-850c-ff46ae344f9a",
   "metadata": {},
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0586dd64-4359-4a48-b456-0d616060409b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Import .py files\n",
    "from dicom_utils import *\n",
    "from helper import *\n",
    "\n",
    "warnings.filterwarnings('ignore') # ignore tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore tensorflow warnings\n",
    "\n",
    "# Import PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import monai model\n",
    "from monai.networks.nets import resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e32687-8399-4288-8df0-cc83037820f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory to root\n",
    "os.chdir('/')\n",
    "data_dir = \"data/classification\" \n",
    "save_dir = \"group/bagel/Task_2/Final\" \n",
    "csv_path = f\"{data_dir}/train_labels.csv\"\n",
    "\n",
    "# Model variables\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "N_EPOCHS = 20\n",
    "\n",
    "CONTRAST_KEYS = ['T1wCE']# ['FLAIR' , 'T1w', 'T1wCE', 'T2w']\n",
    "BATCH_SIZE = [8] #8\n",
    "NUM_IMAGES_3D = [21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b987e5-f04c-48fd-810a-99796792af17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m train_dl, validation_dl \u001b[38;5;241m=\u001b[39m get_train_data_generators(csv_path, contrast, n_img_3D, b_s, VAL_SIZE)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#train_dl = get_train_data_generators(csv_path, contrast, n_img_3D, b_s, VAL_SIZE)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m results, model_t, i_t, thresh_t, train_loss, train_accuracy, val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[38;5;66;43;03m#train_dl, \u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[43mvalidation_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                                                                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_val_accuracy \u001b[38;5;241m<\u001b[39m val_accuracy:\n\u001b[1;32m     41\u001b[0m     save_model(model_t, save_dir_train, i_t, scheduler, train_loss, train_accuracy, val_loss, val_accuracy, thresh_t,\n\u001b[1;32m     42\u001b[0m           n_img_3D, b_s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCEWithLogitsLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, contrast)\n",
      "File \u001b[0;32m/group/bagel/Task_2/Final/helper.py:83\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, validation_dl, optimizer, scheduler, criterion, n_epochs, device)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Initialize best model and best AUC\u001b[39;00m\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     85\u001b[0m best_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/group/bagel/Task_2/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/group/bagel/Task_2/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/group/bagel/Task_2/env/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/group/bagel/Task_2/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for contrast in CONTRAST_KEYS:\n",
    "    # Define saving directory \n",
    "    save_dir_train = f\"{save_dir}/models/{contrast}_model\"\n",
    "    # init dictionary and variable\n",
    "    best_val_accuracy = 0\n",
    "    all_results = {}\n",
    "    for b_s in BATCH_SIZE:\n",
    "        for n_img_3D in NUM_IMAGES_3D:\n",
    "        \n",
    "            # Clear CUDA memory\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            # Set the device to GPU\n",
    "            device = torch.device(\"cuda\")\n",
    "            # Create a ResNet10 \n",
    "            model = resnet10(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "            #model = resnet18(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "        \n",
    "            # Create an Adam optimizer and a learning rate scheduler \n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "            milestones = [5, 10, 15] if b_s == 4 else [10, 15]\n",
    "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "            # Create a Binary Cross Entropy with Logits Loss as the criterion for binary classification\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "            # Create Data Loader\n",
    "            set_random_seed(42)\n",
    "            train_dl, validation_dl = get_train_data_generators(csv_path, contrast, n_img_3D, b_s, VAL_SIZE)\n",
    "            #train_dl = get_train_data_generators(csv_path, contrast, n_img_3D, b_s, VAL_SIZE)\n",
    "            \n",
    "            # Training the model\n",
    "            results, model_t, i_t, thresh_t, train_loss, train_accuracy, val_loss, val_accuracy = train_model(model,\n",
    "                                                                                                          train_dl, \n",
    "                                                                                                          #train_dl, \n",
    "                                                                                                          validation_dl, \n",
    "                                                                                                          optimizer, scheduler, \n",
    "                                                                                                          criterion, N_EPOCHS, \n",
    "                                                                                                          device)\n",
    "            if best_val_accuracy < val_accuracy:\n",
    "                save_model(model_t, save_dir_train, i_t, scheduler, train_loss, train_accuracy, val_loss, val_accuracy, thresh_t,\n",
    "                      n_img_3D, b_s, 'BCEWithLogitsLoss', contrast)\n",
    "                best_val_accuracy = val_accuracy\n",
    "                plot_metrics(results, save_dir_train)\n",
    "            all_results[f\"{contrast}_BS_{b_s}_NbIm_{n_img_3D}\"] = results\n",
    "            torch.cuda.empty_cache()\n",
    "    plot_all(save_dir_train, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32f18a-faa9-4cfb-a53a-b9d87b64e2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project MIP Environment",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
