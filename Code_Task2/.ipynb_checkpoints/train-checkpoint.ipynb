{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644f8fa7-ba5a-4094-850c-ff46ae344f9a",
   "metadata": {},
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0586dd64-4359-4a48-b456-0d616060409b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Import .py files\n",
    "from dicom_utils import *\n",
    "from helper import *\n",
    "\n",
    "warnings.filterwarnings('ignore') # ignore tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore tensorflow warnings\n",
    "\n",
    "# Import PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import monai model\n",
    "from monai.networks.nets import resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e32687-8399-4288-8df0-cc83037820f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory to root\n",
    "os.chdir('/')\n",
    "data_dir = \"data/classification\" \n",
    "save_dir = \"group/bagel/Task_2/Final\" \n",
    "csv_path = f\"{data_dir}/train_labels.csv\"\n",
    "\n",
    "# Model variables\n",
    "#TEST_SIZE = 0.1\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "N_EPOCHS = 20\n",
    "\n",
    "CONTRAST_KEYS = ['FLAIR'] #, 'T1w', 'T1wCE', 'T2w']\n",
    "BATCH_SIZE = [8, 4]\n",
    "NUM_IMAGES_3D = [15, 7, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b987e5-f04c-48fd-810a-99796792af17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=0.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Create Data Loader\u001b[39;00m\n\u001b[1;32m     27\u001b[0m set_random_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m train_dl, validation_dl \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_data_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mn_img_3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mb_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVAL_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m     34\u001b[0m results, model_t, i_t, thresh_t, train_loss, train_accuracy, val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m train_model(model,\n\u001b[1;32m     35\u001b[0m                                                                                               train_dl, \n\u001b[1;32m     36\u001b[0m                                                                                               validation_dl, \n\u001b[1;32m     37\u001b[0m                                                                                               optimizer, scheduler, \n\u001b[1;32m     38\u001b[0m                                                                                               criterion, N_EPOCHS, \n\u001b[1;32m     39\u001b[0m                                                                                               device)\n",
      "File \u001b[0;32m/group/bagel/Task_2/Final/dicom_utils.py:105\u001b[0m, in \u001b[0;36mget_train_data_generators\u001b[0;34m(csv_path, data_path, contrast, num_imgs, img_size, batch_size, val_size, verbose)\u001b[0m\n\u001b[1;32m     99\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m ImagesDicomDataset(data\u001b[38;5;241m=\u001b[39mval_df,\n\u001b[1;32m    100\u001b[0m                                  path \u001b[38;5;241m=\u001b[39m data_path,\n\u001b[1;32m    101\u001b[0m                                  mri_type\u001b[38;5;241m=\u001b[39mcontrast, \n\u001b[1;32m    102\u001b[0m                                  num_imgs \u001b[38;5;241m=\u001b[39m num_imgs)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Create dataloader\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m validation_dl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(val_dataset, \n\u001b[1;32m    111\u001b[0m                                             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    112\u001b[0m                                             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    113\u001b[0m                                             pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_dl, validation_dl\n",
      "File \u001b[0;32m~/PjEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:355\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    351\u001b[0m             sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# auto_collation without custom batch_sampler\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     batch_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mBatchSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_last \u001b[38;5;241m=\u001b[39m drop_last\n",
      "File \u001b[0;32m~/PjEnv/lib/python3.10/site-packages/torch/utils/data/sampler.py:262\u001b[0m, in \u001b[0;36mBatchSampler.__init__\u001b[0;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampler: Union[Sampler[\u001b[38;5;28mint\u001b[39m], Iterable[\u001b[38;5;28mint\u001b[39m]], batch_size: \u001b[38;5;28mint\u001b[39m, drop_last: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Since collections.abc.Iterable does not check for `__getitem__`, which\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# is one way for an object to be an iterable, we don't do an `isinstance`\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# check here.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    261\u001b[0m             batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size should be a positive integer value, but got batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(drop_last, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last should be a boolean value, but got drop_last=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_last\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=0.2"
     ]
    }
   ],
   "source": [
    "for contrast in CONTRAST_KEYS:\n",
    "    # Define saving directory \n",
    "    save_dir_train = f\"{save_dir}/best_{contrast}_model\"\n",
    "    # init dictionary and variable\n",
    "    best_val_accuracy = 0\n",
    "    all_results = {}\n",
    "    for b_s in BATCH_SIZE:\n",
    "        for n_img_3D in NUM_IMAGES_3D:\n",
    "        \n",
    "            # Clear CUDA memory\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            # Set the device to GPU\n",
    "            device = torch.device(\"cuda\")\n",
    "            # Create a ResNet10 \n",
    "            model = resnet10(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "        \n",
    "            # Create an Adam optimizer and a learning rate scheduler \n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "            milestones = [5, 10, 15] if b_s == 4 else [10, 15]\n",
    "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "            # Create a Binary Cross Entropy with Logits Loss as the criterion for binary classification\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "            # Create Data Loader\n",
    "            set_random_seed(42)\n",
    "            train_dl, validation_dl = get_train_data_generators(csv_path, data_dir, contrast, \n",
    "                                                                n_img_3D, \n",
    "                                                                b_s, VAL_SIZE)\n",
    "            \n",
    "            # Training the model\n",
    "            results, model_t, i_t, thresh_t, train_loss, train_accuracy, val_loss, val_accuracy = train_model(model,\n",
    "                                                                                                          train_dl, \n",
    "                                                                                                          validation_dl, \n",
    "                                                                                                          optimizer, scheduler, \n",
    "                                                                                                          criterion, N_EPOCHS, \n",
    "                                                                                                          device)\n",
    "            if best_val_accuracy < val_accuracy:\n",
    "                save_model(model_t, save_dir_train, i_t, scheduler, train_loss, train_accuracy, val_loss, val_accuracy, thresh_t,\n",
    "                      n_img_3D, b_s, 'BCEWithLogitsLoss', contrast)\n",
    "                best_val_accuracy = val_accuracy\n",
    "                plot_metrics(results, save_dir_train)\n",
    "            all_results[f\"{contrast}_BS_{b_s}_NbIm_{n_img_3D}\"] = results\n",
    "            torch.cuda.empty_cache()\n",
    "    plot_all(save_dir_train, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c16cf-a65c-4766-8e06-3e2da901aa66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Environment",
   "language": "python",
   "name": "pjenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
