{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on an [example](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb) provided by project Monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPts5JVdkFzV"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cIs0dgikFzW",
    "outputId": "0cf867cd-add4-40e5-e7d9-1d0df87b697c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss, GeneralizedWassersteinDiceLoss, HausdorffDTLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.metrics import HausdorffDistanceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms.transform import MapTransform\n",
    "from monai.utils.enums import TransformBackends\n",
    "from monai.config import KeysCollection\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from collections.abc import Mapping, Hashable\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dlXdXMekFzZ"
   },
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlFINYXYkFzZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root = '../data/segmentation/train/'\n",
    "\n",
    "# Amount of subjects\n",
    "print(len(os.listdir(root)))\n",
    "\n",
    "d = {}\n",
    "d['training'] = []\n",
    "\n",
    "# split the training data into an even amount of folds\n",
    "num_per_fold = len(os.listdir(root)) / 5\n",
    "curr_fold = 0\n",
    "curr_num = 0\n",
    "for traindir in os.listdir(root):\n",
    "    curr_num += 1\n",
    "    if curr_num == num_per_fold - 1:\n",
    "        curr_num = 0\n",
    "        curr_fold += 1        \n",
    "    v = {'fold': curr_fold,\n",
    "         'image': [root+traindir+'/'+f for f in os.listdir(root+traindir) if 'seg' not in f],\n",
    "         'label': [root+traindir+'/'+f for f in os.listdir(root+traindir) if 'seg' in f ][0]\n",
    "        }\n",
    "    d['training'].append(v)\n",
    "    \n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = '../data/segmentation/test/'\n",
    "\n",
    "# Amount of subjects\n",
    "print(len(os.listdir(root)))\n",
    "\n",
    "d = {}\n",
    "d['testing'] = []\n",
    "\n",
    "# split the training data into an even amount of folds\n",
    "num_per_fold = len(os.listdir(root)) / 5\n",
    "curr_fold = 0\n",
    "curr_num = 0\n",
    "for traindir in os.listdir(root):\n",
    "    curr_num += 1\n",
    "    if curr_num == num_per_fold - 1:\n",
    "        curr_num = 0\n",
    "        curr_fold += 1        \n",
    "    v = {'fold': curr_fold,\n",
    "         'image': [root+traindir+'/'+f for f in os.listdir(root+traindir) if 'seg' not in f],\n",
    "         #'label': [root+traindir+'/'+f for f in os.listdir(root+traindir) if 'seg' in f ][0]\n",
    "        }\n",
    "    d['testing'].append(v)\n",
    "    \n",
    "with open('test.json', 'w') as f:\n",
    "    json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up transforms for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG4rc8BSkFza",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MakeLabelDimsd(MapTransform):        \n",
    "    def __init__(self, keys: KeysCollection, allow_missing_keys: bool = False):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "    \n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            img = d[key]\n",
    "            if img.ndim == 4 and img.shape[0] == 1:\n",
    "                img = img.squeeze(0)\n",
    "\n",
    "            # This seperates the ground-truth into all given channels except the background, as it does not fit the model otherwise\n",
    "            result = [img == 1, img == 2, img == 4]\n",
    "            d[key] = torch.stack(result, dim=0) if isinstance(img, torch.Tensor) else np.stack(result, axis=0)\n",
    "        return d\n",
    "    \n",
    "# Same as above but including the background label\n",
    "class TestMakeLabelDimsd(MapTransform):        \n",
    "    def __init__(self, keys: KeysCollection, allow_missing_keys: bool = False):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "    \n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            img = d[key]\n",
    "            if img.ndim == 4 and img.shape[0] == 1:\n",
    "                img = img.squeeze(0)\n",
    "\n",
    "            result = [img == 0, img == 1, img == 2, img == 4]\n",
    "            d[key] = torch.stack(result, dim=0) if isinstance(img, torch.Tensor) else np.stack(result, axis=0)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjXoDL7QkFzb"
   },
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJVvfJdbkFzb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        MakeLabelDimsd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[128, 128, 80], random_size=False),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        MakeLabelDimsd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "val_transform = Compose (\n",
    " [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        MakeLabelDimsd(keys=\"label\"),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "]   \n",
    ")\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        TestMakeLabelDimsd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = Compose (\n",
    " [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\"]),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "]   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN00Z_5vkFzc"
   },
   "source": [
    "## Set up data-loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRA04WbnkFzc",
    "outputId": "fc8d3243-961f-4e15-89d1-3fbf97913be2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "datalist = \"./data.json\"\n",
    "testlist = \"./test.json\"\n",
    "batch_size = 1\n",
    "fold = (0,1)\n",
    "\n",
    "with open(datalist) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data['training']\n",
    "\n",
    "    tr, val, te = [], [], []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold[1]:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "        \n",
    "with open(testlist) as f:\n",
    "    json_data = json.load(f)\n",
    "    json_data = json_data['testing']\n",
    "    te = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d:\n",
    "            te.append(d)\n",
    "            \n",
    "train_ds = Dataset(data=tr, transform=train_transform)\n",
    "train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "val_ds = Dataset(data=val, transform=val_transform)\n",
    "val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "test_ds = Dataset(data=te, transform=val_transform)\n",
    "test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "'''\n",
    "test_ds = Dataset(data=te, transform=val_transform)\n",
    "test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfqhPL5ykFze"
   },
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqKW_wvRkFze"
   },
   "outputs": [],
   "source": [
    "max_epochs = 800\n",
    "val_interval = 5\n",
    "VAL_AMP = True\n",
    "use_pretrained = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)\n",
    "\n",
    "if use_pretrained:\n",
    "    model.load_state_dict(torch.load(os.path.join('./trained models', \"best_metric_model_800.pth\"), map_location=device))\n",
    "    \n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=True, reduction=\"mean\")\n",
    "hausdorff_metric_batch = HausdorffDistanceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "\n",
    "# define inference method\n",
    "def inference(input, model):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(240, 240, 160),\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "# use amp to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_transform,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "            device=\"cpu\",\n",
    "        ),\n",
    "        Activationsd(keys=\"pred\", sigmoid=True),\n",
    "        AsDiscreted(keys=\"pred\", threshold=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "best_metrics_epochs_and_time = [[], [], []]\n",
    "epoch_loss_values = []\n",
    "val_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_ncr = []\n",
    "metric_values_ed = []\n",
    "metric_values_et = []\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        '''\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", step time: {(time.time() - step_start):.4f}\"\n",
    "        )'''\n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        val_loss = 0\n",
    "        step = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                step += 1\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                val_outputs = inference(val_inputs)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "                #outputs = model(val_inputs)\n",
    "                #val_loss += loss_function(outputs, val_labels)\n",
    "\n",
    "            #val_loss_values.append(val_loss/step)\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_ncr = metric_batch[0].item()\n",
    "            metric_values_ncr.append(metric_ncr)\n",
    "            metric_ed = metric_batch[1].item()\n",
    "            metric_values_ed.append(metric_ed)\n",
    "            metric_et = metric_batch[2].item()\n",
    "            metric_values_et.append(metric_et)\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(\"./trained models\", \"best_metric_model_diceCE_800.pth\"),\n",
    "                )\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\" ncr: {metric_ncr:.4f} ed: {metric_ed:.4f} et: {metric_et:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
    "total_time = time.time() - total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"epoch_loss_values.csv\", epoch_loss_values, delimiter=',')\n",
    "np.savetxt(\"metric_values.csv\", metric_values, delimiter=',')\n",
    "np.savetxt(\"metric_values_ncr.csv\", metric_values_ncr, delimiter=',')\n",
    "np.savetxt(\"metric_values_ed.csv\", metric_values_ed, delimiter=',')\n",
    "np.savetxt(\"metric_values_et.csv\", metric_values_et, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make evaluation segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import convert_data_type\n",
    "from monai.metrics.utils import ignore_background\n",
    "from monai.transforms import MeanEnsemble, VoteEnsemble\n",
    "from pathlib import Path \n",
    "from shutil import copytree\n",
    "\n",
    "def get_background(output):\n",
    "    all_labels_tensor = []\n",
    "    for out in decollate_batch(output):\n",
    "        out = post_trans(out)\n",
    "        neg = np.ones(out[0,:,:,:].shape)[np.newaxis,:,:,:]\n",
    "        for i in range(3):\n",
    "            neg = np.subtract(neg, out[i,:,:,:], where=neg != 0)\n",
    "        all_labels_tensor.append(\n",
    "            torch.cat([torch.from_numpy(neg).to(device), out], dim=0))\n",
    "    return torch.stack(all_labels_tensor)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_data, vald in zip(val_loader, val):\n",
    "        model.load_state_dict(torch.load(os.path.join('./trained models', \"best_metric_model_800.pth\"), map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        torch.cuda.empty_cache()    \n",
    "    \n",
    "        val_inputs = val_data[\"image\"].to(device)\n",
    "        out = inference(val_inputs, model)\n",
    "        out = get_background(out)\n",
    "    \n",
    "        # Use argmax along the first dimension to get the original segmentation mask\n",
    "        reversed_mask = np.argmax(out[0].detach().cpu().numpy(), axis=0)\n",
    "        \n",
    "        # Map indices back to the original values (0, 1, 2, 4)\n",
    "        original_mask = np.zeros_like(reversed_mask)\n",
    "        for i, value in enumerate([0, 1, 2, 4]):\n",
    "            original_mask[reversed_mask == i] = value\n",
    "        \n",
    "        i = vald[\"image\"][0].split('/')[-2]\n",
    "        Path(f'./pred/segmentation/{i}').mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(vald[\"label\"], f'./pred/segmentation/{i}')\n",
    "        Path(f'./results/segmentation/{i}').mkdir(parents=True, exist_ok=True)\n",
    "        label_true = nib.load(vald[\"image\"][0])\n",
    "        aff = label_true.affine\n",
    "        \n",
    "        ni_img = nib.Nifti1Image(original_mask.astype('float64'), aff)\n",
    "        nib.save(ni_img, f'./results/segmentation/{i}/{i}_seg.nii.gz')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final submission segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import convert_data_type\n",
    "from monai.metrics.utils import ignore_background\n",
    "from pathlib import Path\n",
    "from shutil import copytree\n",
    "from monai.transforms import MeanEnsemble, VoteEnsemble\n",
    "\n",
    "def get_background(output):\n",
    "    all_labels_tensor = []\n",
    "    for out in decollate_batch(output):\n",
    "        out = post_trans(out)\n",
    "        neg = np.ones(out[0,:,:,:].shape)[np.newaxis,:,:,:]\n",
    "        for i in range(3):\n",
    "            neg = np.subtract(neg, out[i,:,:,:], where=neg != 0)\n",
    "        all_labels_tensor.append(\n",
    "            torch.cat([torch.from_numpy(neg).to(device), out], dim=0))\n",
    "    return torch.stack(all_labels_tensor)\n",
    "\n",
    "\n",
    "ensemble = VoteEnsemble()\n",
    "with torch.no_grad():\n",
    "    for val_data, vald in zip(test_loader, te):\n",
    "        results = []\n",
    "        model.load_state_dict(torch.load(os.path.join('./trained models', \"best_metric_model_800.pth\")))\n",
    "        model.eval()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        val_inputs = val_data[\"image\"].to(device)\n",
    "        out = inference(val_inputs)\n",
    "        out = get_background(out)\n",
    "        \n",
    "        # Use argmax along the first dimension to get the original segmentation mask\n",
    "        reversed_mask = np.argmax(out[0].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        # Map indices back to the original values (0, 1, 2, 4)\n",
    "        original_mask = np.zeros_like(reversed_mask)\n",
    "        for i, value in enumerate([0, 1, 2, 4]):\n",
    "            original_mask[reversed_mask == i] = value\n",
    "        \n",
    "        i = vald[\"image\"][0].split('/')[-2]\n",
    "        Path(f'./results/testing/segmentation/{i}').mkdir(parents=True, exist_ok=True)\n",
    "        label_true = nib.load(vald[\"image\"][0])\n",
    "        aff = label_true.affine\n",
    "        \n",
    "        ni_img = nib.Nifti1Image(original_mask.astype('float64'), aff)\n",
    "        nib.save(ni_img, f'./results/testing/segmentation/{i}/{i}_seg.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "segresnetvae",
   "language": "python",
   "name": "segresnetvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
